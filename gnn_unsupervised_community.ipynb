{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#––– Environment setup –––\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GAE training: 100%|██████████| 200/200 [00:00<00:00, 277.41it/s]\n",
      "Selecting K: 100%|██████████| 5/5 [00:00<00:00, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected K = 5 (silhouette=0.439)\n",
      "GAE+KMeans modularity: 0.2060\n",
      "..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:00, ?it/s]\n",
      "Seeded LPA iterations: 100%|██████████| 5/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeded LPA modularity: 0.4020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "fsame between KMeans & LPA: 0.8088\n",
      "Jaccard between KMeans & LPA: 0.4339\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import GAE, GCNConv\n",
    "from torch_geometric.utils import from_networkx\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "#––– Community‐comparison utilities –––\n",
    "def pairwise_community_pairs(communities):\n",
    "    pairs = set()\n",
    "    for comm in communities:\n",
    "        for u, v in combinations(sorted(comm), 2):\n",
    "            pairs.add((u, v))\n",
    "    return pairs\n",
    "\n",
    "def compute_fsame(c1, c2):\n",
    "    n = sum(len(c) for c in c1)\n",
    "    M = [[len(set(a).intersection(b)) for b in c2] for a in c1]\n",
    "    max_row = sum(max(row) for row in M)\n",
    "    max_col = sum(max(col) for col in zip(*M))\n",
    "    return 0.5 * (max_row + max_col) / n\n",
    "\n",
    "def jaccard_index(c1, c2):\n",
    "    P1 = pairwise_community_pairs(c1)\n",
    "    P2 = pairwise_community_pairs(c2)\n",
    "    a = len(P1 & P2)\n",
    "    b = len(P1 - P2)\n",
    "    c = len(P2 - P1)\n",
    "    return 1.0 if (a + b + c) == 0 else a / (a + b + c)\n",
    "\n",
    "#––– GAE Encoder –––\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "#––– Extract embeddings –––\n",
    "def get_embeddings(data, hidden_dim=64, emb_dim=16, epochs=200, lr=0.01):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GAE(Encoder(data.num_features, hidden_dim, emb_dim)).to(device)\n",
    "    data = data.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=\"GAE training\"):\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        loss = model.recon_loss(z, data.edge_index)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "    return z.cpu().numpy()\n",
    "\n",
    "#––– Evaluation & Visualization –––\n",
    "from networkx.algorithms.community import modularity\n",
    "\n",
    "def evaluate_modularity(G, communities, label):\n",
    "    Q = modularity(G, communities)\n",
    "    print(f\"{label} modularity: {Q:.4f}\")\n",
    "    return Q\n",
    "\n",
    "def draw_communities(edges, communities, title, fname):\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    node_colors = {node: cid for cid, comm in enumerate(communities) for node in comm}\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        node_color=[node_colors[n] for n in G.nodes()],\n",
    "        cmap='tab20',\n",
    "        node_size=150,\n",
    "        alpha=0.9\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "\n",
    "def plot_community_sizes(communities, title, fname, loglog=False):\n",
    "    sizes = sorted([len(c) for c in communities], reverse=True)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    if loglog:\n",
    "        plt.loglog(sizes, marker='o')\n",
    "    else:\n",
    "        plt.bar(range(len(sizes)), sizes)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Community Rank\")\n",
    "    plt.ylabel(\"Size\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname)\n",
    "    plt.close()\n",
    "\n",
    "#––– Seeded Label Propagation –––\n",
    "def seeded_label_propagation(G, init_labels, iterations=10, seed=42):\n",
    "    random.seed(seed)\n",
    "    labels = init_labels.copy()\n",
    "    nodes = list(G.nodes())\n",
    "    for it in tqdm(range(iterations), desc=\"Seeded LPA iterations\"):\n",
    "        random.shuffle(nodes)\n",
    "        for u in nodes:\n",
    "            nbr_labels = [labels[v] for v in G.neighbors(u)]\n",
    "            if not nbr_labels:\n",
    "                continue\n",
    "            counts = Counter(nbr_labels)\n",
    "            max_count = max(counts.values())\n",
    "            choices = [lab for lab, c in counts.items() if c == max_count]\n",
    "            labels[u] = random.choice(choices)\n",
    "    communities = []\n",
    "    for lab in set(labels.values()):\n",
    "        communities.append([n for n, l in labels.items() if l == lab])\n",
    "    return communities\n",
    "\n",
    "#––– Main pipeline –––\n",
    "def main():\n",
    "    # 1) Load dataset\n",
    "    dataset = \"zachary\"  # or \"www\" or \"zachary\"\n",
    "    if dataset == \"coauthorship\":\n",
    "        G_nx = nx.read_edgelist(\"./data/CA-CondMat.txt\", nodetype=int)\n",
    "    elif dataset == \"www\":\n",
    "        G_nx = nx.read_edgelist(\"./data/web-NotreDame.txt\", nodetype=int)\n",
    "    elif dataset == \"zachary\":\n",
    "        G_nx = nx.read_gml(\"./data/karate.gml\", label=\"id\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset\")\n",
    "    G_nx = nx.convert_node_labels_to_integers(G_nx)\n",
    "    edges = list(G_nx.edges())\n",
    "\n",
    "    # 2) Build PyG data\n",
    "    data = from_networkx(G_nx)\n",
    "    data.x = torch.eye(G_nx.number_of_nodes(), dtype=torch.float)\n",
    "\n",
    "    # 3) Get embeddings\n",
    "    emb = get_embeddings(data, epochs=200)\n",
    "\n",
    "    # 4) Choose K by silhouette\n",
    "    best_k, best_score = 3, -1\n",
    "    for k in tqdm(range(2, 7), desc=\"Selecting K\"):\n",
    "        labels = KMeans(n_clusters=k, random_state=42).fit_predict(emb)\n",
    "        score = silhouette_score(emb, labels)\n",
    "        if score > best_score:\n",
    "            best_k, best_score = k, score\n",
    "    print(f\"Selected K = {best_k} (silhouette={best_score:.3f})\")\n",
    "\n",
    "    # 5) GAE+KMeans communities\n",
    "    labels = KMeans(n_clusters=best_k, random_state=42).fit_predict(emb)\n",
    "    km_comms = [[i for i, l in enumerate(labels) if l == c] for c in range(best_k)]\n",
    "\n",
    "    # 6) Evaluate & visualize GAE+KMeans\n",
    "    Q_km = evaluate_modularity(G_nx, km_comms, \"GAE+KMeans\")\n",
    "    draw_communities(edges, km_comms, \"GAE+KMeans Communities\", \"d_km.png\")\n",
    "    plot_community_sizes(km_comms, \"GAE+KMeans Community Sizes\", \"c_km.png\", loglog=True)\n",
    "    print('..')\n",
    "    # 7) Seeded LPA refinement\n",
    "    init_labels = {i: int(l) for i, l in tqdm(enumerate(labels))}\n",
    "    lpa_comms = seeded_label_propagation(G_nx, init_labels, iterations=5, seed=42)\n",
    "\n",
    "    # 8) Evaluate & visualize Seeded LPA\n",
    "    Q_lpa = evaluate_modularity(G_nx, lpa_comms, \"Seeded LPA\")\n",
    "    draw_communities(edges, lpa_comms, \"Seeded LPA Communities\", \"d_lpa.png\")\n",
    "    plot_community_sizes(lpa_comms, \"Seeded LPA Community Sizes\", \"c_lpa.png\", loglog=True)\n",
    "    print('..')\n",
    "    # 9) Compare partitions\n",
    "    fs = compute_fsame(km_comms, lpa_comms)\n",
    "    ji = jaccard_index(km_comms, lpa_comms)\n",
    "    print(f\"fsame between KMeans & LPA: {fs:.4f}\")\n",
    "    print(f\"Jaccard between KMeans & LPA: {ji:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters by silhouette: 3\n",
      "Modularity of first run: 0.3991\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#––– Environment setup & global seed –––\n",
    "SEED = 50\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GAE, GCNConv\n",
    "from torch_geometric.utils import from_networkx\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns\n",
    "from networkx.algorithms.community import modularity\n",
    "\n",
    "#––– Reproducibility & performance –––\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "#––– Metrics –––\n",
    "def pairwise_community_pairs(communities):\n",
    "    pairs = set()\n",
    "    for comm in communities:\n",
    "        for u, v in combinations(sorted(comm), 2):\n",
    "            pairs.add((u, v))\n",
    "    return pairs\n",
    "\n",
    "def compute_fsame(c1, c2):\n",
    "    n = sum(len(c) for c in c1)\n",
    "    M = [[len(set(a).intersection(b)) for b in c2] for a in c1]\n",
    "    max_row = sum(max(row) for row in M)\n",
    "    max_col = sum(max(col) for col in zip(*M))\n",
    "    return 0.5 * (max_row + max_col) / n\n",
    "\n",
    "def jaccard_index(c1, c2):\n",
    "    P1 = pairwise_community_pairs(c1)\n",
    "    P2 = pairwise_community_pairs(c2)\n",
    "    a = len(P1 & P2)\n",
    "    b = len(P1 - P2)\n",
    "    c = len(P2 - P1)\n",
    "    return 1.0 if (a + b + c) == 0 else a / (a + b + c)\n",
    "\n",
    "#––– GAE Encoder –––\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "#––– Extract embeddings –––\n",
    "def get_embeddings(data, hidden_dim=64, emb_dim=16, epochs=100, lr=0.01):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GAE(Encoder(data.num_features, hidden_dim, emb_dim)).to(device)\n",
    "    data = data.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        loss = model.recon_loss(z, data.edge_index)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "    return z.cpu().numpy()\n",
    "\n",
    "#––– Plot helpers –––\n",
    "def plot_community_sizes(communities, title, fname, loglog=False):\n",
    "    sizes = sorted([len(c) for c in communities], reverse=True)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    if loglog:\n",
    "        plt.loglog(sizes, marker='o')\n",
    "    else:\n",
    "        plt.bar(range(len(sizes)), sizes)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Community Rank\")\n",
    "    plt.ylabel(\"Size\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_heatmap(matrix, title, fname):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(matrix, annot=True, fmt=\".2f\", cmap=\"Blues\", square=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Run\")\n",
    "    plt.ylabel(\"Run\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "#––– Seeded Label Propagation –––\n",
    "def seeded_label_propagation(G, init_labels, iterations=10, seed=SEED):\n",
    "    random.seed(seed)\n",
    "    labels = init_labels.copy()\n",
    "    nodes = list(G.nodes())\n",
    "    for _ in range(iterations):\n",
    "        random.shuffle(nodes)\n",
    "        for u in nodes:\n",
    "            nbrs = [labels[v] for v in G.neighbors(u)]\n",
    "            if not nbrs: continue\n",
    "            counts = Counter(nbrs)\n",
    "            max_c = max(counts.values())\n",
    "            choices = [lab for lab, cnt in counts.items() if cnt == max_c]\n",
    "            labels[u] = random.choice(choices)\n",
    "    communities = [[n for n, l in labels.items() if l == lab] for lab in set(labels.values())]\n",
    "    return communities\n",
    "\n",
    "#––– Main pipeline –––\n",
    "def main():\n",
    "    # Load dataset\n",
    "    dataset = \"zachary\"\n",
    "    if dataset == \"coauthorship\":\n",
    "        G_nx = nx.read_edgelist(\"../data/CA-CondMat.txt\", nodetype=int)\n",
    "    elif dataset == \"www\":\n",
    "        G_nx = nx.read_edgelist(\"../data/web-NotreDame.txt\", nodetype=int)\n",
    "    elif dataset == \"zachary\":\n",
    "        G_nx = nx.read_gml(\"./data/karate.gml\", label=\"id\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset\")\n",
    "    G_nx = nx.convert_node_labels_to_integers(G_nx)\n",
    "\n",
    "    # Build PyG data\n",
    "    data = from_networkx(G_nx)\n",
    "    data.x = torch.eye(G_nx.number_of_nodes(), dtype=torch.float)\n",
    "\n",
    "    # Get embeddings\n",
    "    emb = get_embeddings(data, epochs=200)\n",
    "\n",
    "    # 1. Find optimal number of clusters via silhouette\n",
    "    scores = {}\n",
    "    for k in range(2, 4):\n",
    "        km = KMeans(n_clusters=k, random_state=SEED).fit(emb)\n",
    "        scores[k] = silhouette_score(emb, km.labels_)\n",
    "    best_k = max(scores, key=scores.get)\n",
    "    print(f\"Optimal number of clusters by silhouette: {best_k}\")\n",
    "\n",
    "    # 2. Run KMeans 5 times and collect communities\n",
    "    runs = 5\n",
    "    km_communities = []\n",
    "    for i in range(runs):\n",
    "        labels = KMeans(n_clusters=best_k, random_state=SEED + i).fit_predict(emb)\n",
    "        comms = [[n for n, l in enumerate(labels) if l == c] for c in range(best_k)]\n",
    "        km_communities.append(comms)\n",
    "        if i == 0:\n",
    "            plot_community_sizes(comms, f\"Run {i+1} Community Sizes\", f\"community_sizes_run{i+1}_zachary.png\", loglog=True)\n",
    "\n",
    "    # Build confusion matrices for Jaccard and fsame\n",
    "    jaccard_mat = np.zeros((runs, runs))\n",
    "    fsame_mat = np.zeros((runs, runs))\n",
    "    for i in range(runs):\n",
    "        for j in range(runs):\n",
    "            jaccard_mat[i, j] = jaccard_index(km_communities[i], km_communities[j])\n",
    "            fsame_mat[i, j]   = compute_fsame(km_communities[i], km_communities[j])\n",
    "\n",
    "    # Plot and save heatmaps\n",
    "    plot_heatmap(jaccard_mat, \"Jaccard Similarity Across KMeans Runs\", \"jaccard_confusion_zachary.png\")\n",
    "    plot_heatmap(fsame_mat,   \"fsame Similarity Across KMeans Runs\",   \"fsame_confusion_zachary.png\")\n",
    "\n",
    "    # Print modularity for one example\n",
    "    Q_example = modularity(G_nx, km_communities[0])\n",
    "    print(f\"Modularity of first run: {Q_example:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
